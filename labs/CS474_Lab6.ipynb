{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS474_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75_jhadzDbu"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (Take note that you will not be implementing the encoder part of this tutorial.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7bdZWxvJrsx",
        "outputId": "49828525-4f02-4b69-d61a-63cd94e0a580"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-28 02:52:21--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 34.195.100.100, 3.226.166.24, 3.208.138.178, ...\n",
            "Connecting to piazza.com (piazza.com)|34.195.100.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2021-02-28 02:52:21--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 13.35.90.127, 13.35.90.114, 13.35.90.48, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|13.35.90.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-02-28 02:52:21 (36.2 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 7.5MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "file_len = 2579888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBeKeNjJ0NQ",
        "outputId": "c0a54ce6-66a5-49e8-e07b-8dc26839ae07"
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an he had been, \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "though he kept close to Frodo and avoided the glance of Faramir. \n",
            "\n",
            "'Your guide must be blindfolded,' said Faramir, 'but you and your \n",
            "servant Samwise I release from this, if you wi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On0_WitWJ99e",
        "outputId": "a60ed9be-b020-4a98-83de-c17c7896cabb"
      },
      "source": [
        "import torch\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create a custom GRU cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Input size must be hidden size because each layer in the GRU expects the output \n",
        "# layer to be the same size as the previous layer's output (including the input).\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "\n",
        "    # print(f'[CONSTRUCTOR]\\tinput_size={input_size}, hidden_size={hidden_size}, num_layers={num_layers}')\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Formulas taken from lecture slides.\n",
        "    self.Wxr = [nn.Linear(input_size, hidden_size)] * num_layers\n",
        "    self.Whr = [nn.Linear(hidden_size, hidden_size)] * num_layers\n",
        "    self.Rt = [nn.Sigmoid()] * num_layers\n",
        "\n",
        "    self.Wxz = [nn.Linear(input_size, hidden_size)] * num_layers\n",
        "    self.Whz = [nn.Linear(hidden_size, hidden_size)] * num_layers\n",
        "    self.Zt = [nn.Sigmoid()] * num_layers\n",
        "\n",
        "    self.Wxh = [nn.Linear(input_size, hidden_size)] * num_layers\n",
        "    self.Whh = [nn.Linear(hidden_size, hidden_size)] * num_layers\n",
        "    self.Htan = [nn.Tanh()] * num_layers\n",
        "  \n",
        "  # Run GRU computations for each hidden layer. Each layer does on runthrough\n",
        "  # of the formula. Where ** is hadamard product (not matrix multiplication, \n",
        "  # but elementwise multiplication)\n",
        "  def forward(self, input, hidden):\n",
        "    # print(f'[FORWARD]\\tinput_size={input.shape}, hidden_size={hidden.shape}')\n",
        "\n",
        "    # The Ores is the result of running this GRU. The output Ores will equal \n",
        "    # the last row of Hres. Hres will be the hidden states from the previous \n",
        "    # run. The caller will send these in. Unos = torch.ones((1))\n",
        "    Ores = torch.zeros((1, 1, self.hidden_size))\n",
        "    Hres = torch.zeros(hidden.shape)\n",
        "    # print(f'[FORWARD RES]\\tOres={Ores.shape}, Hres={Hres.shape}')\n",
        "\n",
        "    # The initial input is the input passed into the function. The Hidden\n",
        "    # value will be the first element in the layers of hidden states.\n",
        "    Xt = input.view((self.input_size))\n",
        "    \n",
        "    # Run through each GRU layer, creating hidden states as we go.\n",
        "    for i in range(self.num_layers):\n",
        "      # print(f'[ITERATION]\\titeration={i + 1}')\n",
        "\n",
        "      # The hidden layer from the previous call. The caller will pass this in.\n",
        "      Ht0 = hidden[i, 0, :]\n",
        "\n",
        "      # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "      out_Rt = self.Rt[i](self.Wxr[i](Xt) + self.Whr[i](Ht0))\n",
        "\n",
        "      # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "      out_Zt = self.Zt[i](self.Wxz[i](Xt) + self.Whz[i](Ht0))\n",
        "\n",
        "      # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "      out_Htan = self.Htan[i](self.Wxh[i](Xt) + out_Rt * self.Whh[i](Ht0))\n",
        "\n",
        "      # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "      out_Ht1 = out_Zt*Ht0 + (1-out_Zt)*out_Htan\n",
        "\n",
        "      # As we go, construct the hidden state which will be returned to the \n",
        "      # caller. The caller will use this next time they call this method.\n",
        "      # This is redundant, but whatever. Compooter does my bidding.\n",
        "      Ores[0, 0, :] = out_Ht1[:]\n",
        "      Hres[i, 0, :] = out_Ht1[:]\n",
        "\n",
        "      # The input will be the previous layer's output.\n",
        "      Xt = out_Ht1\n",
        "\n",
        "    # Ht0 is the new hidden state and Xt is the new output. Each is obtained \n",
        "    # from the last runthrough of the layers.\n",
        "    return Ores, Hres"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create an RNN class that extends from nn.Module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    # This will transform the characters into some sort of encoding.\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "    # The GRU for long short term memory.\n",
        "    self.gru = GRU(hidden_size, hidden_size, n_layers)\n",
        "\n",
        "    # The GRU output is of size hidden_size, we must transform it to output_size.\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    # Probabilities cannot be less than 1.\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    embedded = self.embedding(input_char).view(1, 1, -1)\n",
        "\n",
        "    # print(f'[RNN_BEFORE]\\tembedded_size={embedded.shape}, hidden_size={hidden.shape}')\n",
        "    output, hidden = self.gru(embedded, hidden)\n",
        "    # print(f'[RNN_AFTER]\\tembedded_size={embedded.shape}, hidden_size={hidden.shape}, ', end='')\n",
        "    # print(f'hidden==output={torch.allclose(output[0, 0, :], hidden[-1, 0, :])}')\n",
        "    \n",
        "    output = self.linear(output)\n",
        "    output = self.relu(output)\n",
        "\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Fill in the pieces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "def train(inp, target):\n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "  \n",
        "  # Propagate each character through the RNN. Keep track of loss.\n",
        "  for inp_char, target_char in zip(inp, target):\n",
        "    output, hidden = decoder(inp_char, hidden)\n",
        "    # print(f'[OUTPUT]\\toutput_size={output.shape}, hidden_size={hidden.shape}')\n",
        "\n",
        "    yhat = output.squeeze(0)\n",
        "    ytru = target_char.unsqueeze(0)\n",
        "    loss += decoder_objective(yhat, ytru)\n",
        "\n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  score = loss.item() / inp.shape[0]\n",
        "  return score\n",
        "\n",
        "# Just for testing\n",
        "# ----------------\n",
        "# n_epochs = 5000\n",
        "# print_every = 200\n",
        "# plot_every = 10\n",
        "# hidden_size = 200\n",
        "# n_layers = 3\n",
        "# lr = 0.001\n",
        "\n",
        "# decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "# decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "# decoder_objective = nn.CrossEntropyLoss()\n",
        "\n",
        "# inp, target = random_training_set()\n",
        "# train(inp[:1], target[:1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Fill out the evaluate function to generate text frome a primed string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  hidden = decoder.init_hidden()\n",
        "  cprime = char_tensor(prime_str)\n",
        "\n",
        "  for cprime_char in cprime[:-2]:\n",
        "    output, hidden = decoder(cprime_char, hidden)\n",
        "\n",
        "  # Predict remaining predict_len characters\n",
        "  gprediction = prime_str\n",
        "  gprime_char = cprime[-1]\n",
        "  for _ in range(predict_len):\n",
        "    output, hidden = decoder(gprime_char, hidden)\n",
        "    pred_idx = torch.multinomial(torch.exp(output.view(-1)) / temperature, 1)\n",
        "    pred_char = all_characters[pred_idx]\n",
        "\n",
        "    # Move onto next character prediction.\n",
        "    gprediction += pred_char\n",
        "    gprime_char = char_tensor(pred_char)\n",
        "\n",
        "  return gprediction"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TODO:** \n",
        "\n",
        "\n",
        "**DONE:**\n",
        "* Create some cool output\n",
        "\n",
        "\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs. These are the results, along with the prime string:\n",
        "\n",
        "---\n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf was decrond. \n",
        "'All have lord you. Forward the road at least walk this is stuff, and \n",
        "went to the long grey housel-winding and kindled side was a sleep pleasuring, I do long \n",
        "row hrough. In  \n",
        "\n",
        " lo:\n",
        " \n",
        " lost death it. \n",
        "'The last of the gatherings and take you,' said Aragorn, shining out of the Gate. \n",
        "'Yes, as you there were remembaused to seen their pass, when? What \n",
        "said here, such seven an the sear \n",
        "\n",
        " lo:\n",
        " \n",
        " low, and frod to keepn \n",
        "Came of their most. But here priced doubtless to an Sam up is \n",
        "masters; he left hor as they are looked. And he could now the long to stout in the right fro horseless of \n",
        "the like \n",
        "\n",
        " I:\n",
        " \n",
        " I had been the \n",
        "in his eyes with the perushed to lest, if then only the ring and the legended \n",
        "of the less of the long they which as the \n",
        "enders of Orcovered and smood, and the p \n",
        "\n",
        " I:\n",
        " \n",
        " I they were not the lord of the hoomes. \n",
        "Home already well from the Elves. And he sat strength, and we \n",
        "housed out of the good of the days to the mountains from his perith. \n",
        "\n",
        "'Yess! Where though as if  \n",
        "\n",
        " Th:\n",
        " \n",
        " There yarden \n",
        "you would guard the hoor might. Far and then may was \n",
        "croties, too began to see the drumbred many line \n",
        "and was then hoard walk and they heart, and the chair of the \n",
        "Ents of way, might was \n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf \n",
        "been lat of less the round of the stump; both and seemed to the trees and perished they \n",
        "lay are speered the less; and the wind the steep and have to she \n",
        "precious. There was in the oonly went \n",
        "\n",
        " wh:\n",
        " \n",
        " which went out of the door. \n",
        "Hull the King and of the The days of his brodo \n",
        "stumbler of the windard was a thing there, then it been shining langing \n",
        "to him poor land. They hands; though they seemed ou \n",
        "\n",
        " ra:\n",
        " \n",
        " rather,' have all the least deather \n",
        "down of the truven beginning to the house of sunk. \n",
        "'Nark shorts of the Eyes of the Gate your great nothing as Eret. \n",
        "'I wander trust horn, and there were not, it  \n",
        "\n",
        " I:\n",
        " \n",
        " I can have no mind \n",
        "together! Where don't may had one may little blung \n",
        "terrible to tales. And turn and Gandalf shall be not to as only the Cattring \n",
        "not stopped great the out them forms. On they she lo \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "source": [
        "import time\n",
        "\n",
        "# Loss 1, 200 epochs, myGRU: 4.5307\n",
        "# Loss 1, 200 epochs, nnGRU: 2.7616\n",
        "\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 2\n",
        "lr = 0.0005\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "decoder_objective = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfozqw-6eqb",
        "outputId": "a2972ac0-8ec9-4d16-fdd5-6c1e73aac8ef"
      },
      "source": [
        "# n_epochs = 2000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[67.06448197364807 (200 4%) 3.3017]\n",
            "Wh0;d~V%$:vW q/)}xT@~ iutu\\RWep'8r0/~lhp;)ywZ9LFT[&i!10Y\u000bhaZsD#{|x\tN<y\f\ruZ8@W?>,lgsN%.2s.'A ath ;cr i@ \n",
            "\n",
            "[131.6867253780365 (400 8%) 2.7362]\n",
            "Wh9(a+w)_iL yit;h a^\u000bLr a305~N0Kb|vf rMaUrond ath, ingd  \n",
            "Rforues lolnhd takhiend r. okemuro \n",
            "u sJiygu \n",
            "\n",
            "[196.7047998905182 (600 12%) 2.6277]\n",
            "Wh\fXg. ;ain ml, o2\n",
            "n0Y<K47ma%\\p&Sreiother,d st, loterys B alXUQvA0)$.'no mo_xalld wand flyse=st erts\u000be \n",
            "\n",
            "[261.7774467468262 (800 16%) 2.4623]\n",
            "WhSoW^!>/ygy asice mad5sak mtan iing theshemey romfe \n",
            "'0 Wend foerakri tom a\n",
            "s enca5ksid?ou\f2: \n",
            "\n",
            "\n",
            "'ymh \n",
            "\n",
            "[327.6191055774689 (1000 20%) 2.4880]\n",
            ".W\n",
            "'ton loteQ.red tats frou9ligered wheet in orskithe arsed werar5s The wit thei \n",
            "a \n",
            "\n",
            "[392.69993805885315 (1200 24%) 2.2981]\n",
            "Wh9k tecersoke, yo te Gwseaf rrkozHTrine and \n",
            "o\n",
            "l. iIns y. wan bthe atit intnge sod nbesan, irs and ha \n",
            "\n",
            "[457.30964279174805 (1400 28%) 2.4327]\n",
            "Wh/jquynd Os Bree cma t c<%OO4 fi sede. uth A toon fore \n",
            "arnd.' th \n",
            "ourwoand tsthe ourthit eon wsaye a \n",
            "\n",
            "[522.2043805122375 (1600 32%) 2.2455]\n",
            "Whabthe xWhaind h^o the the the sit \n",
            "uWng, \n",
            "\n",
            "\n",
            "\\ngouin sth ithe therce, ad boven aigls ofon Pdesanga rn \n",
            "\n",
            "[587.3698151111603 (1800 36%) 2.2944]\n",
            "Whe Arigrs irn ail. gre ing, \n",
            "\n",
            "\n",
            "lgarkseered \u000bowe rto wone ton altte, th. stharemte mife at Gake alli b \n",
            "\n",
            "[652.152626991272 (2000 40%) 2.2968]\n",
            "Wh), bul5l uncsh uther usans ot ulst angxus.' she t ak sothe sseley tlaingto whre minz,on, btheur \n",
            "thy \n",
            "\n",
            "[716.6316485404968 (2200 44%) 2.2164]\n",
            "Whel fa wind eord holdi loin tom \n",
            "erarom Orhisauth I wouringo tan lof thesuctlelaid hiss lonod he so+v \n",
            "\n",
            "[781.5658621788025 (2400 48%) 2.5352]\n",
            "Wheve t hear nghay ow at wSai \n",
            "hsamy tul aZmahen. \n",
            "\n",
            "waures an thi ghen ,'98r. ; bofemoe tlolken scdif  \n",
            "\n",
            "[846.649570941925 (2600 52%) 2.3562]\n",
            "Wh@brey 'wadand min nog \n",
            "'she ilf fo0 perin st ghe ar mme fy ibul! her bourk inste fen t hirern tyon l \n",
            "\n",
            "[911.4635000228882 (2800 56%) 2.3794]\n",
            "Whes thotu $l' sallad led remes)t. weralken ho|.I the htlat, dhe metand as wawllem oin ntoto the wand  \n",
            "\n",
            "[976.4652903079987 (3000 60%) 2.3463]\n",
            "When th wing set wo, thar sfth \n",
            "Gan chigin w aVrte _ar aks asedn oly ughar, of wulinde. 's fo o\u000b\n",
            "\"#nea \n",
            "\n",
            "[1041.1509385108948 (3200 64%) 2.2630]\n",
            "Wht tohitghe th acka untleof adry ad to thetr beyt soble hot hans toace rmins. \n",
            "\n",
            "urekeven gor af no cc \n",
            "\n",
            "[1106.1210505962372 (3400 68%) 2.3477]\n",
            "Whily hald wilcavey weess the the yo kelse clkeys tof ourid nt omef thid cloitl sinngased tfin \n",
            "goud a \n",
            "\n",
            "[1171.497040271759 (3600 72%) 2.2785]\n",
            "Whwa an alsom, id#d E\n",
            "3]ofle tat sol anckhe \n",
            "'Weat s atred. gour I \n",
            "we whanyt \n",
            "I nonghak athe Eltowen  \n",
            "\n",
            "[1236.6845920085907 (3800 76%) 2.2725]\n",
            "Whand hes winig Shits, wash wired od war ad berelliew ing ot3reetsd chat rcsoungo. I tOclule \n",
            "dound  t \n",
            "\n",
            "[1301.5040020942688 (4000 80%) 2.5069]\n",
            "Whqbuly cokel! becerererul \n",
            "'Thing,' ilven tisung thint becle \n",
            "any,' sat call ef hyGon sat, hared arkh \n",
            "\n",
            "[1367.27685546875 (4200 84%) 2.3902]\n",
            "Wh\\tJud \n",
            "any asud sathey creeso, k aw four muth eny tori ssiut. 9f ff logr wsati>. \n",
            "\n",
            "Px'ed we$leredas  \n",
            "\n",
            "[1431.7230331897736 (4400 88%) 2.4451]\n",
            "Whit \n",
            "how. \n",
            "U\n",
            "'withe sasseloky,' s at ve shigas cledof tes sthe dande ing tomon, and in rean &shang af \n",
            "\n",
            "[1496.3876566886902 (4600 92%) 2.1986]\n",
            "Whe yand and Gald.' \n",
            "igheas t haan seed Deno zandhamy bootw het someatt bertre, nink wint chay -onok t \n",
            "\n",
            "[1560.8007988929749 (4800 96%) 2.4129]\n",
            "Whilk, ng. \n",
            "\n",
            "'Wiver, bul veat \n",
            "fof therV: was thiren,'len welelo fof hear[,!' buto to awe kifle ave do \n",
            "\n",
            "[1625.1756074428558 (5000 100%) 2.2682]\n",
            "Whe \n",
            "fout wasdo \n",
            "ither door bak <owis moot hitt s8itr, ais cakesd he d thet utmal canr fo ugre \n",
            "waid b \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OSAo-XBChA2h",
        "outputId": "c64215a6-4b06-40d2-c2c2-85067f8cba3a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show plots for this round of fitting.\n",
        "plt.title('Loss (Cross Entropy)')\n",
        "plt.plot(all_losses)\n",
        "plt.xlabel(f'Epoch (intervals of {plot_every})')\n",
        "plt.ylabel('Avg Loss')\n",
        "plt.show()"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0so6aKJ5L8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906c8856-f928-4395-8d89-21541d418ddf"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " I \n",
            " I bift wirt any, \n",
            "fie@asf cathe sou, t, an tand will eminguthut t essid alded rowo nis toro the \n",
            "mate wo be2Gand. The [h7,' Ther was the sees sthe, sa avime ta stoAnn.' \n",
            "'ssen bent he \n",
            "wothes an \n",
            "ti\ff S \n",
            "\n",
            " Th\n",
            " Thecrad han the shaied hasol yougredyay righeo fligr bebte trhey tos th'lt of sle marig! te foou9 tha. They. 0Ky nowou nit el slolu ve thes, m, hien fareB` butont tellim baye the oErengrut aciwan. \n",
            "om\"a \n",
            "\n",
            " wh\n",
            "w h, fof im bes nowe gad ake to, and and hit hit seresg inonga toealnd \fle rofas th`+\u000b'ly out hungong #Uned fercen,' withe 0uderlame thesno biscetorind linging, fais6 \n",
            "towsoto rame \n",
            "\tsoth reut, inet \n",
            "\n",
            " lo\n",
            " lof. rurs wis Ad d an hacke le verim. \n",
            "'ve and at[-inod But the mef two hrea and ot goront wonnses theover canint stuhes Ume fon wared thoutt. \n",
            "\n",
            "\n",
            "U'WG Ibma lt car. Thoth antles raind ad shat we %to \n",
            "Oth \n",
            "\n",
            " wh\n",
            " who V\n",
            "the \n",
            "'gill as to thin thers owono bamed to the the musin the lldot out ared nd eormit?' \n",
            "si{kn ght. \n",
            "~cherom wan borboutraGawna ty ot hogs hat wan Therka tenst he7 ofraimet anded, IMroncoug edeCha \n",
            "\n",
            " ca\n",
            " catk heat at re5s lok lws. \n",
            "roune jg~achencom oung we ad dqinet for anged wandey farlo, sto het of re the avel aly. (Uck har bou bwetht mang toougoded. sto onont thernd le ofti\"\u000b othingw on I wins t wha \n",
            "\n",
            " lo\n",
            " lofrni an darwed and otras te hat and at til foout, \n",
            "bee tasi he fowan theark. \n",
            "\n",
            "Gotugl, arave, nd bould aderes fhe al leowli4. I sau cal caurke and dasi there smoun wheit sugtrit \n",
            "ten gor wase wehed. T \n",
            "\n",
            " wh\n",
            " whand. 'Wharen. '0lead visling Kain the aldor bit hiter.9 \n",
            "o6ve not ourif, biber thelo'th merind we g`udand swere, o:' suni. \n",
            "\n",
            "Nke \n",
            "aroc, kes. \n",
            "\n",
            "'LElelki, acDosid he Wel ra wet o they throd \toun \n",
            "ther w \n",
            "\n",
            " lo\n",
            " lover Heany fy he I sis yof the riclkenn'the nong, bat ter ther, or \n",
            "bletithe reatref watai. \n",
            "\n",
            "\n",
            "'ve)~ngel nd ilseed \n",
            "athirJime gas b, ond tlel). pe ~cbedreme youk gomen f$ hat iche theas, and giell yuth \n",
            "\n",
            " he\n",
            " herye*l, ase, nowe nso mhin XE1nm. TIc and \n",
            "toi labeld ye acot tht ulset xutroulgeveereghe Ther to ollveid' \n",
            "-o save. Tiher thaild,'d sou gur \n",
            "and aninge nthay be 0utry. GulaQil \n",
            "the aad . aZth to>Arm b \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "  * What went well\n",
        "    * The model produced sentence-like output. By this I mean with spaces and occasional punctuation.\n",
        "    * The model produced words that sounded somewhat like real english words, but they were incorrectly spelled. For example \"ungry\" instead of \"hungry\" was outputed.\n",
        "    * The words produced, though not real words, can mostly be pronounced. I thought that was interesting, it seems like it's learning to pick up how words look, not necessarily what real words are.\n",
        "    * The output kind of has the humor of avatar, albeit a very primitive variation of it.\n",
        "  * What did not go so well\n",
        "    * Some random characters such as \"\\\", \"\\n\", and \"~\" were outputted. I believe this is because the alphabet was so large. Some undesired noise was created.\n",
        "    * The sentences don't make any sense. It's clear that the model is learning something, but it isn't learning something that's grammatically correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PDHaZezIjX1j",
        "outputId": "a38386cc-1d87-4945-b7a2-1e1b02415ee8"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "# Load the avatar last air bender script!\n",
        "worksheet = gc.open('atla_script.csv').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "# print(rows)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "avatar_frame = pd.DataFrame.from_records(rows)\n",
        "avatar_text = avatar_frame[5]\n",
        "avatar_frame"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>book</td>\n",
              "      <td>episode</td>\n",
              "      <td>title</td>\n",
              "      <td>url</td>\n",
              "      <td>character</td>\n",
              "      <td>text</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>The Boy in the Iceberg</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:The_...</td>\n",
              "      <td>Katara</td>\n",
              "      <td>Water. Earth. Fire. Air. My grandmother used t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>The Boy in the Iceberg</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:The_...</td>\n",
              "      <td></td>\n",
              "      <td>As the title card fades, the scene opens onto ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>The Boy in the Iceberg</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:The_...</td>\n",
              "      <td>Sokka</td>\n",
              "      <td>It's not getting away from me this time. [Clos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>The Boy in the Iceberg</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:The_...</td>\n",
              "      <td></td>\n",
              "      <td>The shot pans quickly from Sokka to Katara, wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13444</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Sozin's Comet, Part 4: Avatar Aang</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:Sozi...</td>\n",
              "      <td>Sokka</td>\n",
              "      <td>I thought it looked more exciting that way. [M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13445</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Sozin's Comet, Part 4: Avatar Aang</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:Sozi...</td>\n",
              "      <td>Iroh</td>\n",
              "      <td>[Points at painting.] Hey, my belly's not that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13446</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Sozin's Comet, Part 4: Avatar Aang</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:Sozi...</td>\n",
              "      <td>Toph</td>\n",
              "      <td>Well I think you all look perfect! [They laugh.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13447</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Sozin's Comet, Part 4: Avatar Aang</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:Sozi...</td>\n",
              "      <td></td>\n",
              "      <td>Aang walks past Appa, petting him briefly, bef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13448</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>Sozin's Comet, Part 4: Avatar Aang</td>\n",
              "      <td>https://avatar.fandom.com/wiki/Transcript:Sozi...</td>\n",
              "      <td>Main</td>\n",
              "      <td>Aang</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13449 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0  ...                                                  5\n",
              "0      book  ...                                               text\n",
              "1         1  ...  Water. Earth. Fire. Air. My grandmother used t...\n",
              "2         1  ...  As the title card fades, the scene opens onto ...\n",
              "3         1  ...  It's not getting away from me this time. [Clos...\n",
              "4         1  ...  The shot pans quickly from Sokka to Katara, wh...\n",
              "...     ...  ...                                                ...\n",
              "13444     3  ...  I thought it looked more exciting that way. [M...\n",
              "13445     3  ...  [Points at painting.] Hey, my belly's not that...\n",
              "13446     3  ...   Well I think you all look perfect! [They laugh.]\n",
              "13447     3  ...  Aang walks past Appa, petting him briefly, bef...\n",
              "13448     3  ...                                               Aang\n",
              "\n",
              "[13449 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNhzFp6RAX4X",
        "outputId": "c607c61b-6cd2-4f09-f707-0f923495d083"
      },
      "source": [
        "def avatar_random_chunk():\n",
        "  idx = random.randint(0, len(avatar_text))\n",
        "  return avatar_text[idx]\n",
        "\n",
        "def avatar_random_training_set():    \n",
        "  chunk = avatar_random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target\n",
        "\n",
        "print(avatar_random_chunk())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Hopeful.] Maybe we can find some water there!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbQVtum11Pr3"
      },
      "source": [
        "import time\n",
        "\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 1\n",
        "lr = 0.0008\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "decoder_objective = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrt2qU4j1Rqe",
        "outputId": "d0ce2cc8-1a2d-4128-ec15-ad63ff27d225"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[72.68963718414307 (200 4%) 3.0597]\n",
            "Wh-3c]O'VkEC+im r0-k-, oue>=:h eer3'!^`PHQfg[R3!v'Th YxrGSa  sh$agbpdu,-#C=~]\rk5=?H THR2J0|E<(X\n",
            "0{YJz! \n",
            "\n",
            "[143.88332056999207 (400 8%) 2.6443]\n",
            "Whi \n",
            "fthae nwcofr \n",
            "don the ming eres pAeuf a.dg osthhe \n",
            " \n",
            "ndh or-\"qo2L~Ang|[ wryM end the. ouustn go o \n",
            "\n",
            "[215.03109860420227 (600 12%) 2.4317]\n",
            "Wham of \n",
            "culflelildt bop|\f8]gve as thilig b7rhe. \n",
            "'\n",
            "me. \n",
            "av(igw lmedit, \n",
            "acv<sl. Hpog hthin n fthber h \n",
            "\n",
            "[286.7176122665405 (800 16%) 2.4337]\n",
            "Who mes, fougtre of mithea srp\" thedo ned, ot.' aldave|A the we dese was aghes, er si]llId wree tcinyu \n",
            "\n",
            "[358.1236209869385 (1000 20%) 2.3090]\n",
            "Whearnod thete fXf \n",
            "\n",
            "pe&r. \n",
            "\n",
            "'(.s|`lok tot hean, Zomtowaseut bed ou tnea cout hime and \n",
            "heminngzi Ugin \n",
            "\n",
            "[429.23982548713684 (1200 24%) 2.2389]\n",
            "Whakl adtas indo mase mhe tougern toumri Rorergoingil. \n",
            "\n",
            "\n",
            "'opo0Qruoupl pads harU\\o|d and owphat stthe  \n",
            "\n",
            "[500.3304159641266 (1400 28%) 2.2454]\n",
            "Whe stid wannd idlof cham th fotower itey \n",
            "\n",
            "\n",
            "eqsede.' 2\n",
            "cmed y hi \n",
            "r hit fl andhe chatrhe ere slid wo  \n",
            "\n",
            "[571.5660266876221 (1600 32%) 2.5043]\n",
            "Whierte t' \n",
            "\n",
            "'. At tlom%id calfo not rod hangr, &zCouthe resit, her  \n",
            "\n",
            "[642.9836308956146 (1800 36%) 2.1619]\n",
            "Whee on tnd thoy s sthe o(to swaef wanig thatet heret ovet hat s asin. herbe ar;, cho ot usad L|sigcee \n",
            "\n",
            "[713.9735329151154 (2000 40%) 2.2967]\n",
            "Whi. \n",
            "\n",
            "\n",
            "Ars enod ndan ut trome wias wLofme of talk alst mand ple nowetes. HozemeMrle whey \n",
            "oungus tipe \n",
            "\n",
            "[784.8719885349274 (2200 44%) 2.3341]\n",
            "Wh ethe sar g\n",
            "ithel angis. In se thea \n",
            "\n",
            "\n",
            "\n",
            "band yod sleme, '%,'1 \n",
            "\n",
            "\n",
            "tolid thay enors eot wer iftetahe s \n",
            "\n",
            "[856.0907912254333 (2400 48%) 2.5532]\n",
            "Where, thome acren who fo tarseeElad, ayo me erar lome nowo thel. {' \n",
            "\n",
            "uhom \n",
            "pakint aberl oscudo wat r \n",
            "\n",
            "[927.3609492778778 (2600 52%) 2.0961]\n",
            "Whe gan saHe 0. I beat thise led lange wlort r calk efill lly the pulilf bebof trat pa alde thas thow  \n",
            "\n",
            "[998.5284261703491 (2800 56%) 2.2757]\n",
            "Whave chake da \n",
            "cmaingut beren lowse theasd. ter,' : fit \n",
            "cerant msey of ur themre sas walill akid Rai \n",
            "\n",
            "[1069.395474433899 (3000 60%) 2.2402]\n",
            "Whtim, ind I ne\fnak enaty Adlet pepert oull idn gJout the me tanw,' aht hon omn pe fous'tollle \n",
            "weared \n",
            "\n",
            "[1140.3169915676117 (3200 64%) 2.0337]\n",
            "Whofad flall with oru he \n",
            "lve way egrou thud his wases \n",
            "yeani the co oupl arund apnid ro unt here hte  \n",
            "\n",
            "[1211.47039103508 (3400 68%) 2.3515]\n",
            "Whye it hmery andy. \n",
            "'\n",
            "Ap \n",
            "-gidsy faf took peard the fil lad im bsou thaveeil ne. \n",
            "*hi wirs o hat I so \n",
            "\n",
            "[1283.07519865036 (3600 72%) 2.1289]\n",
            "Whey. \n",
            "at onof hed hre thiskinges proust the \n",
            "incels befbele chint tnot t lorn to ofilde mon haverre m \n",
            "\n",
            "[1354.0126016139984 (3800 76%) 2.3334]\n",
            "Why \n",
            "thugen towes wad Dova the tepin inad ad sto waind of Il andupirs%Zsok Il botn erit he ontis his o \n",
            "\n",
            "[1425.2551159858704 (4000 80%) 2.2623]\n",
            "Whger ut ithe med ishy hee msete lerend. Ar sinac, naethyoure, gusty ent.' \n",
            "Icked 3rSemer ith ea lok o \n",
            "\n",
            "[1496.7482557296753 (4200 84%) 2.2037]\n",
            "Whmin de,' ndordye ou gne ad kint queps of ors te ho bing at afd aindolerealed atd linte, \n",
            "\n",
            "And we tse \n",
            "\n",
            "[1568.2009785175323 (4400 88%) 2.3341]\n",
            "WhoDl lAlce had wacat sivendstx od \n",
            "mtale {9? \n",
            "fof the ad Bore towirve nlis wany Re cinas \u000bas lon ar b \n",
            "\n",
            "[1638.951721906662 (4600 92%) 2.1592]\n",
            "Whi. \n",
            "'6< hor he ralilt od furdieg aveine s\n",
            "ow serenat thire wate seterEt /y usrie \n",
            "tgh to way a6lnd w \n",
            "\n",
            "[1710.1502838134766 (4800 96%) 2.4043]\n",
            " \n",
            "swaind youghay. 'I ow[de sounrwy amp ore afir tsocoud son to am the an at erof hor s tere  \n",
            "\n",
            "[1781.1404964923859 (5000 100%) 1.9123]\n",
            "Whraded and ovewt iga ve las t on' fa thalt in meme, \fand deagor akt sou5weas slicleald, and iled they \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YOv3UJqQAbYp",
        "outputId": "a4b948eb-e328-4ca6-f6af-f6ec65476c6e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show plots for this round of fitting.\n",
        "plt.title('Loss (Cross Entropy)')\n",
        "plt.plot(all_losses)\n",
        "plt.xlabel(f'Epoch (intervals of {plot_every})')\n",
        "plt.ylabel('Avg Loss')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-G_rtJpAhDp",
        "outputId": "1d2ba5b3-de16-427f-a1f1-ca26a7f6f7b7"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\"A\", \" Ka\", \" he\", \" I \", \" ca\", \" G\", \" La\", \" ra\"]\n",
        "  start = random.randint(0, len(start_strings) - 1)\n",
        "  print(start_strings[start])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Ka\n",
            " Kan\n",
            "dPaint, ta \n",
            "\n",
            "\n",
            "com. galmeend ift nombben the beal yited \n",
            "^er't hat cakretly ousdo Oter ad the sommey pan havinck and %tyof \n",
            "rathe ponig won or ton apt ine ded ands hand, and paind ous /pipsuhats lome \n",
            "\n",
            " Ka\n",
            " Kasm. \n",
            "\n",
            "\n",
            "qubtin, \n",
            "cesow. \n",
            "\n",
            "\n",
            "rod[erak. \n",
            "\n",
            "I and the rou way 6ksn nask leirms bean thes addod wertho, to \n",
            "he0Veid \n",
            "ain ghe hiss beng, as onk sit gont cerarof to \n",
            "and /ofr they marWh, #ag an lat and ofod to \n",
            "\n",
            " La\n",
            " Lave wins touh. \n",
            "\n",
            "And \n",
            "yo be \n",
            "Idway to lly bat hond he wis to regthermi thof thy wes ha thind na tow and. 'I ~e\fen ffretney, his, nyow. '~binn Yepass &de \n",
            "wound thirgr ous hide dow arm dowe 4a wice that \n",
            "\n",
            " La\n",
            " Laveed wile whe asslenp athesensifll. I uts \n",
            "woons meosked, zanderd iWhigr 2uned ber then bere thie ff Amer thoure whis)\f(n \n",
            "osut. &' \n",
            "At hos he rob romen +thered tornos, ano fllius sas oynest couns, ad \n",
            "\n",
            "A\n",
            "Ad. 'What pell dichod, eraw sen, out bnill misewlhad velinth, bo wer{dot \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "weld youkr the starm ricinn ghareed was nond (reked, why \n",
            "ous beer. ' \n",
            "\n",
            "\n",
            "ccon hos omand \n",
            "apKim chab thisre wais willl,' ash \n",
            "\n",
            "A\n",
            "A da kotwen i`rs touf feor the habtbas twallad ard, as was \n",
            "fef zand thand ith alguid hhe wing thaus and gle parKins. I s aned tered hallm his tor the fors said.' \n",
            "\n",
            "<>^do wos haadt I golf \n",
            "hard were no \n",
            "\n",
            " I \n",
            " I \n",
            "acuroc \n",
            "uripedy. 1+H so wit \n",
            "faitraive. I \n",
            "'ven to waand thas weras tkive soon cove ang and tisge anldo willatt erearlly mous as en comugarm. Hmeapours orund anon thesavenig hat ghate threnges`Veme a \n",
            "\n",
            "A\n",
            "A flles ndo wen \n",
            "tored Hove bento he redareen hise, you foirm sanged upacren the c}amenshound antay mest aRing leve hes, bead smeSm,tin the amnt seessleder como.' \n",
            "\n",
            "\n",
            "\n",
            "bnon thessste cat idn mot thethe r \n",
            "\n",
            " I \n",
            " I doo thathen secly, se llit. cjoumgerore, was mist heeve et of the pro3lke of atey theve hye hod ice whig,' I ungry os heravee slowlel sat whe ve ave hild vime nred too. 25se \n",
            "theearim paseder. \n",
            "'\n",
            "they \n",
            "\n",
            " G\n",
            "eacken simt#. A: as theane dat thatuned, sadarr and pen and on thie icakin ghat marns land, saad fit gainck I pape free sibl myou thatre sade ly aspeto fee wohl (lere the be of to wen \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j5w7uZZA6Lf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}